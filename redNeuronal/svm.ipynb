{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def read_and_create_data(filename):\n",
    "    if filename == 'Iris.csv':\n",
    "        \n",
    "        df = pd.read_csv(filename)\n",
    "\n",
    "        np.random.seed(9)\n",
    "        df_train = df\n",
    "        df_test = df\n",
    "        _Y = df_train[df_train.columns[-1:]]\n",
    "        _X = df_train[df_train.columns[:4]].apply(\n",
    "            lambda x: (x - x.min())/(x.max() - x.min()))\n",
    "\n",
    "        y_test = df_test[df_test.columns[-1:]]\n",
    "        X_test = df_test[df_test.columns[:4]].apply(\n",
    "            lambda x: (x - x.min())/(x.max() - x.min()))\n",
    "\n",
    "        return _X, _Y, X_test, y_test\n",
    "    else:\n",
    "        df = pd.read_csv(filename)\n",
    "        np.random.seed(9)\n",
    "        df_train = df\n",
    "        df_test = df\n",
    "        _Y = df_train[df_train.columns[-1:]]\n",
    "        _X = df_train[df_train.columns[:13]].apply(\n",
    "            lambda x: (x-x.min())/(x.max()-x.min()))\n",
    "        y_test = df_test[df_test.columns[-1:]]\n",
    "        X_test = df_test[df_test.columns[:13]].apply(\n",
    "            lambda x: (x - x.min())/(x.max() - x.min()))\n",
    "\n",
    "        return _X, _Y, X_test, y_test\n",
    "\n",
    "    \n",
    "def leer_datos(dataset):\n",
    "    data = pd.read_csv(dataset) \n",
    "    x = data.iloc[:,:-1]\n",
    "    y = data.iloc[:,-1]\n",
    "    return x,y\n",
    "\n",
    "def normalizar_datos(x):\n",
    "    x_media = x.mean(axis=0)\n",
    "    x_std = x.std(axis=0)\n",
    "    x  = (x - x_media)/x_std\n",
    "    return x\n",
    "\n",
    "def dividir_datos(X, y, porcentaje):\n",
    "    X_train, X_test, y_train, y_test = train_test_split( x, y, test_size=porcentaje, random_state=42)\n",
    "    return X_train, X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(303, 13)\n"
     ]
    }
   ],
   "source": [
    "x,y = leer_datos('heart.csv')\n",
    "print (x.shape)\n",
    "# a,b,c = crear_k_folds('Iris.csv', 3)\n",
    "# print (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6138613861386139, 0.5346534653465347, 0.5445544554455446]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "accuracyPromedio = []\n",
    "def leer_folds(filename, kernel):\n",
    "    indexFor = 0;\n",
    "    n_csv = 0\n",
    "    while indexFor < 3:\n",
    "        if filename == \"Iris.csv\":\n",
    "            _X = TrainProbandoX = pd.read_csv('foldsIris' + str(n_csv) + '.csv', usecols = ['0', '1', '2', '3'])\n",
    "            _y = TrainProbandoY = pd.read_csv('foldsIris' + str(n_csv+1) + '.csv', usecols = ['0'])\n",
    "            _X_test = pd.read_csv('foldsIris' +  str(n_csv+2)+'.csv', usecols = ['0', '1', '2', '3'])\n",
    "            _y_test = pd.read_csv('foldsIris' + str(n_csv+3) + '.csv', usecols = ['0'])\n",
    "\n",
    "            _X = normalizar_datos(_X)\n",
    "            _X_test = normalizar_datos(_X_test)\n",
    "            print (_X)\n",
    "            print (_y)\n",
    "            clf = SVC(C=15.0,kernel='rbf',gamma=10.0)\n",
    "            clf.fit(_X, _y)\n",
    "            \n",
    "            accuracyPromedio.append(clf.score(_X_test, _y_test))\n",
    "            indexFor = indexFor+1\n",
    "            n_csv = n_csv + 4\n",
    "        else:\n",
    "            _X = TrainProbandoX = pd.read_csv('folds' + str(n_csv) + '.csv', usecols = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12'])\n",
    "            _y = TrainProbandoY = pd.read_csv('folds' + str(n_csv+1) + '.csv', usecols = ['0'])\n",
    "            _X_test = pd.read_csv('folds' +  str(n_csv+2)+'.csv', usecols = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12'])\n",
    "            _y_test = pd.read_csv('folds' + str(n_csv+3) + '.csv', usecols = ['0'])\n",
    "\n",
    "            _X = normalizar_datos(_X)\n",
    "            _X_test = normalizar_datos(_X_test)\n",
    "\n",
    "            \n",
    "            clf = SVC(C=1.0,kernel=kernel,gamma=1.0)\n",
    "            clf.fit(_X, _y.values.ravel())\n",
    "            accuracyPromedio.append(clf.score(_X_test, _y_test))\n",
    "            \n",
    "            indexFor = indexFor+1\n",
    "            n_csv = n_csv + 4\n",
    "    return _X, _y, _X_test, _y_test\n",
    "leer_folds(\"heart.csv\", 'rbf')\n",
    "print (accuracyPromedio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/darkar/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma=1.0, kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# _X, _y, _X_test, _y_test = leer_folds()\n",
    "from sklearn.svm import SVC\n",
    "clf = SVC(C=1.0,kernel='rbf',gamma=1.0)\n",
    "clf.fit(_X, _y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] [1]\n",
      "[1] [1]\n",
      "[1] [1]\n",
      "[1] [1]\n",
      "[1] [1]\n",
      "[0] [1]\n",
      "[1] [1]\n",
      "[1] [1]\n",
      "[1] [1]\n",
      "[1] [1]\n",
      "[0] [1]\n",
      "[1] [1]\n",
      "[1] [1]\n",
      "[1] [1]\n",
      "[1] [1]\n",
      "[1] [1]\n",
      "[1] [1]\n",
      "[1] [1]\n",
      "[0] [1]\n",
      "[1] [1]\n",
      "[0] [1]\n",
      "[1] [1]\n",
      "[0] [1]\n",
      "[1] [1]\n",
      "[1] [1]\n",
      "[1] [1]\n",
      "[1] [1]\n",
      "[1] [1]\n",
      "[1] [1]\n",
      "[1] [1]\n",
      "[1] [1]\n",
      "[0] [1]\n",
      "[1] [1]\n",
      "[1] [1]\n",
      "[1] [1]\n",
      "[1] [1]\n",
      "[1] [1]\n",
      "[1] [1]\n",
      "[1] [1]\n",
      "[1] [1]\n",
      "[1] [1]\n",
      "[1] [1]\n",
      "[1] [1]\n",
      "[1] [1]\n",
      "[1] [1]\n",
      "[1] [1]\n",
      "[1] [1]\n",
      "[1] [1]\n",
      "[1] [1]\n",
      "[1] [1]\n",
      "[1] [1]\n",
      "[0] [1]\n",
      "[0] [1]\n",
      "[1] [1]\n",
      "[1] [1]\n",
      "[1] [0]\n",
      "[0] [0]\n",
      "[0] [0]\n",
      "[0] [0]\n",
      "[0] [0]\n",
      "[1] [0]\n",
      "[1] [0]\n",
      "[1] [0]\n",
      "[1] [0]\n",
      "[0] [0]\n",
      "[1] [0]\n",
      "[0] [0]\n",
      "[0] [0]\n",
      "[0] [0]\n",
      "[0] [0]\n",
      "[0] [0]\n",
      "[0] [0]\n",
      "[1] [0]\n",
      "[1] [0]\n",
      "[0] [0]\n",
      "[1] [0]\n",
      "[0] [0]\n",
      "[0] [0]\n",
      "[1] [0]\n",
      "[1] [0]\n",
      "[1] [0]\n",
      "[0] [0]\n",
      "[0] [0]\n",
      "[0] [0]\n",
      "[1] [0]\n",
      "[0] [0]\n",
      "[1] [0]\n",
      "[0] [0]\n",
      "[0] [0]\n",
      "[0] [0]\n",
      "[1] [0]\n",
      "[0] [0]\n",
      "[0] [0]\n",
      "[1] [0]\n",
      "[0] [0]\n",
      "[0] [0]\n",
      "[0] [0]\n",
      "[0] [0]\n",
      "[1] [0]\n",
      "[0] [0]\n",
      "[1] [0]\n",
      "0.7326732673267327\n"
     ]
    }
   ],
   "source": [
    "asserts = 0\n",
    "for x, y in zip(_X_test.values, _y_test.values):\n",
    "    #print (x.reshape(-1,13))\n",
    "    #predicted = clf.predict(x.reshape(-1,13))\n",
    "    predicted = clf.predict(x.reshape(-1,4))\n",
    "    #print(predicted)\n",
    "    #print ('predecido')\n",
    "    print(predicted, y)\n",
    "    if (y == predicted).all():\n",
    "        asserts += 1\n",
    "print(asserts/_X_test.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7326732673267327"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(_X_test, _y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'a' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-9f0b75368ea0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'a' is not defined"
     ]
    }
   ],
   "source": [
    "sets = np.array([a,b,c])\n",
    "print (sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sets' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-c0a353ea5df3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0melemente\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpermut\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m#print(elemente)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mtrain_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0melemente\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0melemente\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;31m#print(train_set)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sets' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf1 = SVC(C=1.0,kernel='rbf',gamma=1.0)\n",
    "\n",
    "permut = np.array([[0, 1, 2], [0 , 2 , 1], [1, 2, 0]])\n",
    "vec_acc = ([])\n",
    "for elemente in permut:\n",
    "    #print(elemente)\n",
    "    train_set = np.concatenate((sets[elemente[0]], sets[elemente[1]]))\n",
    "    #print(train_set)\n",
    "    X_train = train_set[:,:-1]\n",
    "    X_train = normalizar_datos(X_train)\n",
    "    y_train = train_set[:,-1]\n",
    "        \n",
    "    test_set = sets[elemente[2]]\n",
    "    X_test = test_set[:,:-1]\n",
    "    X_test = normalizar_datos(X_test)\n",
    "    #print(X_test)\n",
    "    y_test = test_set[:,-1]\n",
    "    print(y_test)\n",
    "    clf1.fit(X_train, y_train)\n",
    "    print (clf1.score(X_test, y_test))\n",
    "    #vec_acc = np.append(vec_acc,acc)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
