{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VS2Iq_SJc9J9"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from copy import copy\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "erC6rIZddzZD"
   },
   "outputs": [],
   "source": [
    "def read_and_create_data(filename):\n",
    "    if filename == 'Iris.csv':\n",
    "        \n",
    "        df = pd.read_csv(filename)\n",
    "        df2 = df.join(pd.get_dummies(df.pop('Species')))\n",
    "\n",
    "        np.random.seed(9)\n",
    "        df_train = df2\n",
    "        df_test = df2\n",
    "        _Y = df_train[df_train.columns[-3:]]\n",
    "        _X = df_train[df_train.columns[:4]].apply(\n",
    "            lambda x: (x - x.min())/(x.max() - x.min()))\n",
    "\n",
    "        y_test = df_test[df_test.columns[-3:]]\n",
    "        X_test = df_test[df_test.columns[:4]].apply(\n",
    "            lambda x: (x - x.min())/(x.max() - x.min()))\n",
    "\n",
    "        return _X, _Y, X_test, y_test\n",
    "    else:\n",
    "        df = pd.read_csv(filename)\n",
    "        np.random.seed(9)\n",
    "        df_train = df\n",
    "        df_test = df\n",
    "        _Y = df_train[df_train.columns[-1:]]\n",
    "        _X = df_train[df_train.columns[:13]].apply(\n",
    "            lambda x: (x-x.min())/(x.max()-x.min()))\n",
    "        y_test = df_test[df_test.columns[-1:]]\n",
    "        X_test = df_test[df_test.columns[:13]].apply(\n",
    "            lambda x: (x - x.min())/(x.max() - x.min()))\n",
    "\n",
    "        return _X, _Y, X_test, y_test\n",
    "\n",
    "def leer_datos(dataset):\n",
    "    data = pd.read_csv(dataset) \n",
    "    x = data.iloc[:,:-1]\n",
    "    y = data.iloc[:,-1]\n",
    "    return x,y\n",
    "\n",
    "def normalizar_datos(x):\n",
    "    x_media = x.mean(axis=0)\n",
    "    x_std = x.std(axis=0)\n",
    "    x  = (x - x_media)/x_std\n",
    "    return x\n",
    "\n",
    "def dividir_datos(X, y, porcentaje):\n",
    "    X_train, X_test, y_train, y_test = train_test_split( x, y, test_size=porcentaje, random_state=42)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X1hjXmgXeKED",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "_X1, _y1, _X_test1, _y_test1 = read_and_create_data('heart.csv')\n",
    "_X, _X_test, _y, _y_test = train_test_split( _X1, _y1, test_size=0.30, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fhiA13l8fDNx"
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1.0 - x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WYyYCzxHfKJz"
   },
   "outputs": [],
   "source": [
    "class HiddenLayer(object):\n",
    "    def __init__(self, n_input, n_output, function_activation,\n",
    "                 last_layer=False, W=None, b=None):\n",
    "        self.n_input = n_input\n",
    "        self.n_output = n_output\n",
    "        self.function_activation = function_activation\n",
    "        self.W = W\n",
    "        self.b = b\n",
    "        self.last_layer = last_layer\n",
    "        if not self.W:\n",
    "            # Random Weights\n",
    "            # self.W = np.random.normal(0,1,(n_input, n_output))\n",
    "            # self.W = normalize(self.W)\n",
    "            self.W = 2.0*np.random.random((n_input, n_output))-1.0\n",
    "            self.W /= np.sqrt(n_input)\n",
    "            # self.W = np.amax(np.random.normal(0,1,(n_input, n_output)), axis=0)\n",
    "        if not self.b:\n",
    "            self.b = 2.0*np.random.random((1, n_output))-1.0\n",
    "\n",
    "        \n",
    "    def get_activations(self, input, penum=False):\n",
    "        self.activations = self.function_activation(\n",
    "            np.dot(input, self.W))\n",
    "        return self.activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZSY5f0BgfXJy"
   },
   "outputs": [],
   "source": [
    "class MLP(object):\n",
    "    def __init__(self, n_hidden_layers, n_activations, n_input, n_output):\n",
    "        self.n_hidden_layers = n_hidden_layers\n",
    "        self.n_activations = n_activations\n",
    "        self.n_input = n_input\n",
    "        self.function_activation = sigmoid\n",
    "        self.function_derivative = sigmoid_derivative\n",
    "        # Add first layer\n",
    "\n",
    "        self.hidden_layers = [\n",
    "            HiddenLayer(\n",
    "                self.n_input,\n",
    "                self.n_activations,\n",
    "                self.function_activation\n",
    "            )\n",
    "        ]\n",
    "        # print(self.hidden_layers[0].W.shape)\n",
    "        for i in range(self.n_hidden_layers-1):\n",
    "            layer_to_append = HiddenLayer(\n",
    "                # how n_input use the size of columns of\n",
    "                # the weights in the last layer\n",
    "                self.n_activations,\n",
    "                self.n_activations,\n",
    "                self.function_activation\n",
    "            )\n",
    "            self.hidden_layers.append(layer_to_append)\n",
    "\n",
    "        # Add last layer\n",
    "        self.hidden_layers.append(\n",
    "            HiddenLayer(\n",
    "                self.n_activations,\n",
    "                n_output,\n",
    "                sigmoid,\n",
    "                last_layer=True\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def forward(self, input, activations=list(), final_activations=list()):\n",
    "        activations.append(input)\n",
    "        last_activation = input\n",
    "        final_activations.append(last_activation)\n",
    "\n",
    "        for hidden_layer in self.hidden_layers[:-1]:\n",
    "            last_activation = hidden_layer.get_activations(last_activation)\n",
    "            activations.append(last_activation)\n",
    "        #    last_activation = np.append(np.array([1.0]), last_activation)\n",
    "            final_activations.append(last_activation)\n",
    "\n",
    "        last_activation = self.hidden_layers[-1].get_activations(\n",
    "            last_activation)\n",
    "        activations.append(last_activation)\n",
    "\n",
    "        return last_activation\n",
    "\n",
    "    def calculate_cost(self, X, y):\n",
    "        y_pred_test = self.forward(X)\n",
    "        first_to_sum = y * np.log(y_pred_test)\n",
    "        second_to_sum = (1 - y) * np.log(1 - y_pred_test)\n",
    "        to_sum = first_to_sum + second_to_sum\n",
    "        return (-(1/(X.shape[0])) * np.sum(to_sum)).mean()\n",
    "\n",
    "    def sklearn_cost(self, X, y):\n",
    "        y_pred_test = np.apply_along_axis(self.forward, 1, X)\n",
    "        return log_loss(y, y_pred_test)\n",
    "\n",
    "    def backward(self, X, y):\n",
    "        activations = []\n",
    "        final_activations = []\n",
    "        tmp_forward = self.forward(X, activations, final_activations)\n",
    "\n",
    "        deltas = []\n",
    "        current_activation = activations[len(activations)-1]\n",
    "        current_update_activation = activations[len(activations)-2]\n",
    "        last_delta = (y - current_activation) * self.function_derivative(\n",
    "            current_activation)\n",
    "        deltas.append(np.dot(current_update_activation.T, last_delta))\n",
    "        activations.pop()\n",
    "        for hidden_layer in reversed(self.hidden_layers[1:]):\n",
    "            current_activation = activations[len(activations) - 1]\n",
    "            current_update_activation = activations[len(activations) - 2]\n",
    "            last_delta = np.dot(\n",
    "                last_delta, hidden_layer.W.T\n",
    "            ) * self.function_derivative(current_activation)\n",
    "            deltas.append(np.dot(current_update_activation.T, last_delta))\n",
    "            activations.pop()\n",
    "        deltas.reverse()\n",
    "        return deltas\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JoVmBdnUf4wZ"
   },
   "outputs": [],
   "source": [
    "def plot_cost_history(iterations, cost_history):\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    ax.set_ylabel('J(Theta)')\n",
    "    ax.set_xlabel('Iterations')\n",
    "    _ = ax.plot(range(iterations), cost_history, 'g.')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zlWB93KOgCl2"
   },
   "outputs": [],
   "source": [
    "mlp = MLP(1, 10, 13, 1)\n",
    "learning_rate = 0.07\n",
    "iterations = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sHKIjZUNgI8d"
   },
   "outputs": [],
   "source": [
    "cost_history = np.zeros(iterations)\n",
    "last_error = mlp.calculate_cost(_X, _y)\n",
    "accuracyPromedio = []\n",
    "def precision(_X_test, _y_test, filename):\n",
    "    index = 0\n",
    "    assertsArray = []\n",
    "    asserts = 0\n",
    "    _X_test = normalizar_datos(_X_test)\n",
    "    for x, y in zip(_X_test.values, _y_test.values):\n",
    "        if filename == \"Iris.csv\":\n",
    "            predicted = mlp.forward(x)\n",
    "            print(predicted)\n",
    "            predicted[0] = 1 if predicted[0] > 0.5 else 0\n",
    "            predicted[1] = 1 if predicted[1] > 0.5 else 0\n",
    "            predicted[2] = 1 if predicted[2] > 0.5 else 0\n",
    "            print(predicted, y)\n",
    "            if (y == predicted).all():\n",
    "                asserts += 1\n",
    "        else:\n",
    "            predicted = mlp.forward(x)\n",
    "            print(predicted)\n",
    "            predicted[0] = 1 if predicted[0] > 0.5 else 0\n",
    "            print(predicted, y)\n",
    "            if (y == predicted).all():\n",
    "                asserts += 1\n",
    "    assertsArray.append(asserts/_X_test.shape[0])\n",
    "    index = index + 1\n",
    "    return assertsArray\n",
    "\n",
    "def experimento(model, learning_rate, iterations, filename, last_error, cost_history):\n",
    "    indexFor = 0;\n",
    "    n_csv = 0\n",
    "    while indexFor < 3:\n",
    "        if filename == \"Iris.csv\":\n",
    "            _X = TrainProbandoX = pd.read_csv('foldsIris' + str(n_csv) + '.csv', usecols = ['0', '1', '2', '3'])\n",
    "            _y = TrainProbandoY = pd.read_csv('foldsIris' + str(n_csv+1) + '.csv', usecols = ['0'])\n",
    "            _X_test = pd.read_csv('foldsIris' +  str(n_csv+2)+'.csv', usecols = ['0', '1', '2', '3'])\n",
    "            _y_test = pd.read_csv('foldsIris' + str(n_csv+3) + '.csv', usecols = ['0'])\n",
    "\n",
    "            _y = _y.join(pd.get_dummies(_y.pop('0')))\n",
    "            _y_test = _y_test.join(pd.get_dummies(_y_test.pop('0')))\n",
    "\n",
    "            _X = normalizar_datos(_X)\n",
    "            for itr in range(iterations):\n",
    "                _X, _y = shuffle(_X, _y, random_state=1)\n",
    "                deltas = mlp.backward(_X, _y)\n",
    "                index = len(mlp.hidden_layers) - 1\n",
    "                while index >= 0:\n",
    "                    mlp.hidden_layers[index].W += (deltas[index] * learning_rate)\n",
    "                    index -= 1\n",
    "                last_error = mlp.calculate_cost(_X, _y)\n",
    "                cost_history[itr] = last_error\n",
    "            accuracyPromedio.append(precision(_X_test, _y_test, \"Iris.csv\"))\n",
    "            indexFor = indexFor+1\n",
    "            n_csv = n_csv + 4\n",
    "        else:\n",
    "            _X = TrainProbandoX = pd.read_csv('folds' + str(n_csv) + '.csv', usecols = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12'])\n",
    "            _y = TrainProbandoY = pd.read_csv('folds' + str(n_csv+1) + '.csv', usecols = ['0'])\n",
    "            _X_test = pd.read_csv('folds' +  str(n_csv+2)+'.csv', usecols = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12'])\n",
    "            _y_test = pd.read_csv('folds' + str(n_csv+3) + '.csv', usecols = ['0'])\n",
    "\n",
    "            _X = normalizar_datos(_X)\n",
    "            for itr in range(iterations):\n",
    "                _X, _y = shuffle(_X, _y, random_state=1)\n",
    "                deltas = mlp.backward(_X, _y)\n",
    "                index = len(mlp.hidden_layers) - 1\n",
    "                while index >= 0:\n",
    "                    mlp.hidden_layers[index].W += (deltas[index] * learning_rate)\n",
    "                    index -= 1\n",
    "                last_error = mlp.calculate_cost(_X, _y)\n",
    "                cost_history[itr] = last_error\n",
    "            accuracyPromedio.append(precision(_X_test, _y_test, \"heart.csv\"))\n",
    "            indexFor = indexFor+1\n",
    "            n_csv = n_csv + 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95682638]\n",
      "[1.] [1]\n",
      "[0.88417949]\n",
      "[1.] [1]\n",
      "[0.9803538]\n",
      "[1.] [1]\n",
      "[0.99430482]\n",
      "[1.] [1]\n",
      "[0.96731915]\n",
      "[1.] [1]\n",
      "[0.84324596]\n",
      "[1.] [1]\n",
      "[0.96551444]\n",
      "[1.] [1]\n",
      "[0.99922504]\n",
      "[1.] [1]\n",
      "[0.78387109]\n",
      "[1.] [1]\n",
      "[0.99945721]\n",
      "[1.] [1]\n",
      "[0.18979042]\n",
      "[0.] [1]\n",
      "[0.99818763]\n",
      "[1.] [1]\n",
      "[0.99429978]\n",
      "[1.] [1]\n",
      "[0.99919615]\n",
      "[1.] [1]\n",
      "[0.93372195]\n",
      "[1.] [1]\n",
      "[0.99978806]\n",
      "[1.] [1]\n",
      "[0.99651677]\n",
      "[1.] [1]\n",
      "[0.60043362]\n",
      "[1.] [1]\n",
      "[0.63065626]\n",
      "[1.] [1]\n",
      "[0.99953942]\n",
      "[1.] [1]\n",
      "[0.51614236]\n",
      "[1.] [1]\n",
      "[0.99616339]\n",
      "[1.] [1]\n",
      "[0.97374425]\n",
      "[1.] [1]\n",
      "[0.43287444]\n",
      "[0.] [1]\n",
      "[0.074526]\n",
      "[0.] [1]\n",
      "[0.24900482]\n",
      "[0.] [1]\n",
      "[0.98012795]\n",
      "[1.] [1]\n",
      "[0.97635605]\n",
      "[1.] [1]\n",
      "[0.39574988]\n",
      "[0.] [1]\n",
      "[0.93704798]\n",
      "[1.] [1]\n",
      "[0.9951435]\n",
      "[1.] [1]\n",
      "[0.45204016]\n",
      "[0.] [1]\n",
      "[0.98496629]\n",
      "[1.] [1]\n",
      "[0.30887735]\n",
      "[0.] [1]\n",
      "[0.24515848]\n",
      "[0.] [1]\n",
      "[0.99529482]\n",
      "[1.] [1]\n",
      "[0.99005041]\n",
      "[1.] [1]\n",
      "[0.42050862]\n",
      "[0.] [1]\n",
      "[0.8751746]\n",
      "[1.] [1]\n",
      "[0.57600855]\n",
      "[1.] [1]\n",
      "[0.40315093]\n",
      "[0.] [1]\n",
      "[0.82328409]\n",
      "[1.] [1]\n",
      "[0.19671368]\n",
      "[0.] [1]\n",
      "[0.72169193]\n",
      "[1.] [1]\n",
      "[0.91241388]\n",
      "[1.] [1]\n",
      "[0.97995748]\n",
      "[1.] [1]\n",
      "[0.92694731]\n",
      "[1.] [1]\n",
      "[0.78682929]\n",
      "[1.] [1]\n",
      "[0.99993459]\n",
      "[1.] [1]\n",
      "[0.99836341]\n",
      "[1.] [1]\n",
      "[0.99931756]\n",
      "[1.] [1]\n",
      "[0.46028571]\n",
      "[0.] [1]\n",
      "[0.11699692]\n",
      "[0.] [1]\n",
      "[0.999989]\n",
      "[1.] [1]\n",
      "[0.98870252]\n",
      "[1.] [1]\n",
      "[7.90048014e-05]\n",
      "[0.] [0]\n",
      "[0.19927684]\n",
      "[0.] [0]\n",
      "[0.69039606]\n",
      "[1.] [0]\n",
      "[0.21143927]\n",
      "[0.] [0]\n",
      "[0.01906298]\n",
      "[0.] [0]\n",
      "[0.78270155]\n",
      "[1.] [0]\n",
      "[0.46496304]\n",
      "[0.] [0]\n",
      "[0.97682286]\n",
      "[1.] [0]\n",
      "[0.05981574]\n",
      "[0.] [0]\n",
      "[0.01067161]\n",
      "[0.] [0]\n",
      "[0.89451914]\n",
      "[1.] [0]\n",
      "[0.17475715]\n",
      "[0.] [0]\n",
      "[0.96537573]\n",
      "[1.] [0]\n",
      "[0.67377325]\n",
      "[1.] [0]\n",
      "[0.00061079]\n",
      "[0.] [0]\n",
      "[0.00022672]\n",
      "[0.] [0]\n",
      "[0.2076083]\n",
      "[0.] [0]\n",
      "[0.99594279]\n",
      "[1.] [0]\n",
      "[0.31085803]\n",
      "[0.] [0]\n",
      "[0.0037891]\n",
      "[0.] [0]\n",
      "[0.88923099]\n",
      "[1.] [0]\n",
      "[0.00949509]\n",
      "[0.] [0]\n",
      "[0.00241367]\n",
      "[0.] [0]\n",
      "[0.13381314]\n",
      "[0.] [0]\n",
      "[0.97345803]\n",
      "[1.] [0]\n",
      "[0.02987853]\n",
      "[0.] [0]\n",
      "[0.01928702]\n",
      "[0.] [0]\n",
      "[0.05762595]\n",
      "[0.] [0]\n",
      "[1.13654305e-05]\n",
      "[0.] [0]\n",
      "[0.99476914]\n",
      "[1.] [0]\n",
      "[0.00113951]\n",
      "[0.] [0]\n",
      "[0.3822323]\n",
      "[0.] [0]\n",
      "[0.85265331]\n",
      "[1.] [0]\n",
      "[0.09535234]\n",
      "[0.] [0]\n",
      "[0.00350351]\n",
      "[0.] [0]\n",
      "[0.61701139]\n",
      "[1.] [0]\n",
      "[0.00044156]\n",
      "[0.] [0]\n",
      "[0.54813826]\n",
      "[1.] [0]\n",
      "[0.02130342]\n",
      "[0.] [0]\n",
      "[0.01164333]\n",
      "[0.] [0]\n",
      "[0.0035815]\n",
      "[0.] [0]\n",
      "[0.0544331]\n",
      "[0.] [0]\n",
      "[0.00033149]\n",
      "[0.] [0]\n",
      "[0.01117021]\n",
      "[0.] [0]\n",
      "[0.63997603]\n",
      "[1.] [0]\n",
      "[0.9529994]\n",
      "[1.] [0]\n",
      "[0.99730901]\n",
      "[1.] [1]\n",
      "[0.89976542]\n",
      "[1.] [1]\n",
      "[0.81645481]\n",
      "[1.] [1]\n",
      "[0.99997251]\n",
      "[1.] [1]\n",
      "[0.99928759]\n",
      "[1.] [1]\n",
      "[0.99996384]\n",
      "[1.] [1]\n",
      "[0.99642213]\n",
      "[1.] [1]\n",
      "[0.99999855]\n",
      "[1.] [1]\n",
      "[0.99999904]\n",
      "[1.] [1]\n",
      "[0.99995941]\n",
      "[1.] [1]\n",
      "[0.99983517]\n",
      "[1.] [1]\n",
      "[0.96614935]\n",
      "[1.] [1]\n",
      "[0.9997673]\n",
      "[1.] [1]\n",
      "[0.99999944]\n",
      "[1.] [1]\n",
      "[0.99978714]\n",
      "[1.] [1]\n",
      "[0.99035849]\n",
      "[1.] [1]\n",
      "[0.81094804]\n",
      "[1.] [1]\n",
      "[0.99989248]\n",
      "[1.] [1]\n",
      "[0.99931877]\n",
      "[1.] [1]\n",
      "[0.99999995]\n",
      "[1.] [1]\n",
      "[0.99983715]\n",
      "[1.] [1]\n",
      "[0.89039522]\n",
      "[1.] [1]\n",
      "[0.99504029]\n",
      "[1.] [1]\n",
      "[0.99999039]\n",
      "[1.] [1]\n",
      "[0.74567875]\n",
      "[1.] [1]\n",
      "[0.99999779]\n",
      "[1.] [1]\n",
      "[0.9905565]\n",
      "[1.] [1]\n",
      "[0.99999998]\n",
      "[1.] [1]\n",
      "[0.99776171]\n",
      "[1.] [1]\n",
      "[0.9994532]\n",
      "[1.] [1]\n",
      "[0.96907153]\n",
      "[1.] [1]\n",
      "[0.16790165]\n",
      "[0.] [1]\n",
      "[0.99873408]\n",
      "[1.] [1]\n",
      "[0.99999746]\n",
      "[1.] [1]\n",
      "[0.97679652]\n",
      "[1.] [1]\n",
      "[0.99785532]\n",
      "[1.] [1]\n",
      "[0.97577984]\n",
      "[1.] [1]\n",
      "[0.94005978]\n",
      "[1.] [1]\n",
      "[0.96797681]\n",
      "[1.] [1]\n",
      "[0.99999857]\n",
      "[1.] [1]\n",
      "[0.26609973]\n",
      "[0.] [1]\n",
      "[0.92851003]\n",
      "[1.] [1]\n",
      "[0.97581794]\n",
      "[1.] [1]\n",
      "[0.99927125]\n",
      "[1.] [1]\n",
      "[0.97852358]\n",
      "[1.] [1]\n",
      "[0.99875037]\n",
      "[1.] [1]\n",
      "[0.9110291]\n",
      "[1.] [1]\n",
      "[0.99989804]\n",
      "[1.] [1]\n",
      "[0.61582115]\n",
      "[1.] [1]\n",
      "[0.99999708]\n",
      "[1.] [1]\n",
      "[0.99978123]\n",
      "[1.] [1]\n",
      "[0.99865925]\n",
      "[1.] [1]\n",
      "[0.98228669]\n",
      "[1.] [1]\n",
      "[0.99999991]\n",
      "[1.] [1]\n",
      "[0.99945934]\n",
      "[1.] [1]\n",
      "[1.57936185e-07]\n",
      "[0.] [0]\n",
      "[0.02551786]\n",
      "[0.] [0]\n",
      "[0.18371945]\n",
      "[0.] [0]\n",
      "[0.00130877]\n",
      "[0.] [0]\n",
      "[0.00380504]\n",
      "[0.] [0]\n",
      "[0.82277391]\n",
      "[1.] [0]\n",
      "[5.87432033e-09]\n",
      "[0.] [0]\n",
      "[4.6473121e-05]\n",
      "[0.] [0]\n",
      "[9.32578083e-05]\n",
      "[0.] [0]\n",
      "[2.22918809e-08]\n",
      "[0.] [0]\n",
      "[0.00197655]\n",
      "[0.] [0]\n",
      "[0.45914824]\n",
      "[0.] [0]\n",
      "[3.13268789e-07]\n",
      "[0.] [0]\n",
      "[4.62924238e-07]\n",
      "[0.] [0]\n",
      "[9.82505552e-05]\n",
      "[0.] [0]\n",
      "[0.00223898]\n",
      "[0.] [0]\n",
      "[0.0059888]\n",
      "[0.] [0]\n",
      "[0.99179315]\n",
      "[1.] [0]\n",
      "[0.23391409]\n",
      "[0.] [0]\n",
      "[0.99999186]\n",
      "[1.] [0]\n",
      "[3.6449296e-08]\n",
      "[0.] [0]\n",
      "[0.00036905]\n",
      "[0.] [0]\n",
      "[0.00031308]\n",
      "[0.] [0]\n",
      "[1.68793417e-06]\n",
      "[0.] [0]\n",
      "[0.00024325]\n",
      "[0.] [0]\n",
      "[0.00077254]\n",
      "[0.] [0]\n",
      "[6.99263789e-05]\n",
      "[0.] [0]\n",
      "[0.00146972]\n",
      "[0.] [0]\n",
      "[0.01136367]\n",
      "[0.] [0]\n",
      "[0.42198661]\n",
      "[0.] [0]\n",
      "[0.35715685]\n",
      "[0.] [0]\n",
      "[0.71224084]\n",
      "[1.] [0]\n",
      "[0.00273442]\n",
      "[0.] [0]\n",
      "[0.00396385]\n",
      "[0.] [0]\n",
      "[0.02660257]\n",
      "[0.] [0]\n",
      "[0.00021359]\n",
      "[0.] [0]\n",
      "[0.02375389]\n",
      "[0.] [0]\n",
      "[0.00255504]\n",
      "[0.] [0]\n",
      "[0.00035568]\n",
      "[0.] [0]\n",
      "[9.84350495e-06]\n",
      "[0.] [0]\n",
      "[1.29593571e-07]\n",
      "[0.] [0]\n",
      "[0.71019226]\n",
      "[1.] [0]\n",
      "[0.00054089]\n",
      "[0.] [0]\n",
      "[0.99994129]\n",
      "[1.] [0]\n",
      "[0.00021041]\n",
      "[0.] [0]\n",
      "[1.02125494e-08]\n",
      "[0.] [0]\n",
      "[0.99613341]\n",
      "[1.] [1]\n",
      "[0.71230679]\n",
      "[1.] [1]\n",
      "[0.99997523]\n",
      "[1.] [1]\n",
      "[0.88002578]\n",
      "[1.] [1]\n",
      "[0.99979283]\n",
      "[1.] [1]\n",
      "[0.99999996]\n",
      "[1.] [1]\n",
      "[0.82289283]\n",
      "[1.] [1]\n",
      "[0.94212196]\n",
      "[1.] [1]\n",
      "[0.99999998]\n",
      "[1.] [1]\n",
      "[0.89874218]\n",
      "[1.] [1]\n",
      "[0.76727313]\n",
      "[1.] [1]\n",
      "[0.99960016]\n",
      "[1.] [1]\n",
      "[0.99986088]\n",
      "[1.] [1]\n",
      "[0.99999935]\n",
      "[1.] [1]\n",
      "[0.99999999]\n",
      "[1.] [1]\n",
      "[0.99980274]\n",
      "[1.] [1]\n",
      "[0.99968554]\n",
      "[1.] [1]\n",
      "[0.99999964]\n",
      "[1.] [1]\n",
      "[0.99999639]\n",
      "[1.] [1]\n",
      "[0.97961367]\n",
      "[1.] [1]\n",
      "[1.]\n",
      "[1.] [1]\n",
      "[0.9999869]\n",
      "[1.] [1]\n",
      "[0.99859807]\n",
      "[1.] [1]\n",
      "[0.99999838]\n",
      "[1.] [1]\n",
      "[0.99999974]\n",
      "[1.] [1]\n",
      "[0.99996007]\n",
      "[1.] [1]\n",
      "[0.99990039]\n",
      "[1.] [1]\n",
      "[0.65389229]\n",
      "[1.] [1]\n",
      "[0.13171904]\n",
      "[0.] [1]\n",
      "[0.69660033]\n",
      "[1.] [1]\n",
      "[0.99998585]\n",
      "[1.] [1]\n",
      "[0.47588644]\n",
      "[0.] [1]\n",
      "[0.99999996]\n",
      "[1.] [1]\n",
      "[0.99054349]\n",
      "[1.] [1]\n",
      "[0.99999756]\n",
      "[1.] [1]\n",
      "[0.9987856]\n",
      "[1.] [1]\n",
      "[0.9999993]\n",
      "[1.] [1]\n",
      "[0.9999908]\n",
      "[1.] [1]\n",
      "[0.99999644]\n",
      "[1.] [1]\n",
      "[0.99997801]\n",
      "[1.] [1]\n",
      "[0.00040876]\n",
      "[0.] [1]\n",
      "[0.99130105]\n",
      "[1.] [1]\n",
      "[0.47395452]\n",
      "[0.] [1]\n",
      "[0.98961609]\n",
      "[1.] [1]\n",
      "[0.99999951]\n",
      "[1.] [1]\n",
      "[0.99643359]\n",
      "[1.] [1]\n",
      "[0.99994924]\n",
      "[1.] [1]\n",
      "[0.99999411]\n",
      "[1.] [1]\n",
      "[0.29558324]\n",
      "[0.] [1]\n",
      "[0.82948588]\n",
      "[1.] [1]\n",
      "[0.99869992]\n",
      "[1.] [1]\n",
      "[0.99999802]\n",
      "[1.] [1]\n",
      "[0.99999991]\n",
      "[1.] [1]\n",
      "[0.83849463]\n",
      "[1.] [1]\n",
      "[0.83849463]\n",
      "[1.] [1]\n",
      "[3.64006359e-06]\n",
      "[0.] [0]\n",
      "[0.00536229]\n",
      "[0.] [0]\n",
      "[0.17084487]\n",
      "[0.] [0]\n",
      "[1.45242291e-05]\n",
      "[0.] [0]\n",
      "[0.0682117]\n",
      "[0.] [0]\n",
      "[4.70270033e-09]\n",
      "[0.] [0]\n",
      "[0.00102741]\n",
      "[0.] [0]\n",
      "[0.01700354]\n",
      "[0.] [0]\n",
      "[0.00504576]\n",
      "[0.] [0]\n",
      "[0.05474003]\n",
      "[0.] [0]\n",
      "[0.00453167]\n",
      "[0.] [0]\n",
      "[3.90610963e-12]\n",
      "[0.] [0]\n",
      "[1.39537474e-07]\n",
      "[0.] [0]\n",
      "[6.29462206e-05]\n",
      "[0.] [0]\n",
      "[1.28748626e-05]\n",
      "[0.] [0]\n",
      "[0.0036953]\n",
      "[0.] [0]\n",
      "[0.00081322]\n",
      "[0.] [0]\n",
      "[2.91794968e-08]\n",
      "[0.] [0]\n",
      "[5.51579478e-05]\n",
      "[0.] [0]\n",
      "[1.70149618e-05]\n",
      "[0.] [0]\n",
      "[0.48701472]\n",
      "[0.] [0]\n",
      "[0.02372951]\n",
      "[0.] [0]\n",
      "[9.02920737e-08]\n",
      "[0.] [0]\n",
      "[1.38586469e-06]\n",
      "[0.] [0]\n",
      "[0.00722623]\n",
      "[0.] [0]\n",
      "[0.00369627]\n",
      "[0.] [0]\n",
      "[0.00235596]\n",
      "[0.] [0]\n",
      "[7.94759044e-07]\n",
      "[0.] [0]\n",
      "[3.14159778e-10]\n",
      "[0.] [0]\n",
      "[0.78225855]\n",
      "[1.] [0]\n",
      "[0.0038775]\n",
      "[0.] [0]\n",
      "[3.1785198e-12]\n",
      "[0.] [0]\n",
      "[0.073089]\n",
      "[0.] [0]\n",
      "[0.00617523]\n",
      "[0.] [0]\n",
      "[0.00011614]\n",
      "[0.] [0]\n",
      "[2.64284275e-05]\n",
      "[0.] [0]\n",
      "[0.0063845]\n",
      "[0.] [0]\n",
      "[2.2453668e-06]\n",
      "[0.] [0]\n",
      "[1.06502502e-09]\n",
      "[0.] [0]\n",
      "[0.03080677]\n",
      "[0.] [0]\n",
      "[4.72333694e-05]\n",
      "[0.] [0]\n",
      "[0.03328334]\n",
      "[0.] [0]\n",
      "[0.05509472]\n",
      "[0.] [0]\n",
      "[3.6549285e-06]\n",
      "[0.] [0]\n",
      "[0.00016299]\n",
      "[0.] [0]\n",
      "[0.2177399]\n",
      "[0.] [0]\n"
     ]
    }
   ],
   "source": [
    "experimento(mlp, learning_rate, iterations, \"heart.csv\", last_error, cost_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "49jUfXXagjgf"
   },
   "outputs": [],
   "source": [
    "# _X = normalizar_datos(_X)\n",
    "# for itr in range(iterations):\n",
    "#     _X, _y = shuffle(_X, _y, random_state=1)\n",
    "#     deltas = mlp.backward(_X, _y)\n",
    "#     index = len(mlp.hidden_layers) - 1\n",
    "#     while index >= 0:\n",
    "#         mlp.hidden_layers[index].W += (deltas[index] * learning_rate)\n",
    "#         index -= 1\n",
    "#     last_error = mlp.calculate_cost(_X, _y)\n",
    "#     cost_history[itr] = last_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1578
    },
    "colab_type": "code",
    "id": "nDxBN_xuhG0k",
    "outputId": "89d03fb0-598b-454f-e350-0850b5fedba8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.7227722772277227], [0.9207920792079208], [0.9405940594059405]]\n",
      "0.8613861386138614\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "print (accuracyPromedio)\n",
    "def promedioAccuracy (accuracyPromedio):\n",
    "    promedio = 0\n",
    "    for index in accuracyPromedio:\n",
    "        promedio = promedio + index[0]\n",
    "    print (promedio / len(accuracyPromedio))\n",
    "promedioAccuracy(accuracyPromedio)\n",
    "# asserts = 0\n",
    "# _X_test = normalizar_datos(_X_test)\n",
    "# for x, y in zip(_X_test.values, _y_test.values):\n",
    "#     predicted = mlp.forward(x)\n",
    "#     print(predicted)\n",
    "#     predicted[0] = 1 if predicted[0] > 0.5 else 0\n",
    "#     predicted[1] = 1 if predicted[1] > 0.5 else 0\n",
    "#     predicted[2] = 1 if predicted[2] > 0.5 else 0\n",
    "#     print(predicted, y)\n",
    "#     if (y == predicted).all():\n",
    "#         asserts += 1\n",
    "# print(asserts/_X_test.shape[0])\n",
    "plot_cost_history(iterations, cost_history)\n",
    "\n",
    "# asserts = 0\n",
    "# _X_test = normalizar_datos(_X_test)\n",
    "# for x, y in zip(_X_test.values, _y_test.values):\n",
    "#     predicted = mlp.forward(x)\n",
    "#     print(predicted)\n",
    "#     predicted[0] = 1 if predicted[0] > 0.5 else 0\n",
    "#     print(predicted, y)\n",
    "#     if (y == predicted).all():\n",
    "#         asserts += 1\n",
    "# print(asserts/_X_test.shape[0])\n",
    "# plot_cost_history(iterations, cost_history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "MLP_iris.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
