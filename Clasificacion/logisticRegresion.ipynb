{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np   \n",
    "import pandas as pd  \n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def leer_datos(dataset):\n",
    "    data = pd.read_csv(dataset) \n",
    "    x = data.iloc[:,:-1]\n",
    "    y = data.iloc[:,-1]\n",
    "    return x,y\n",
    "\n",
    "def normalizar_datos(x):\n",
    "    x_media = x.mean(axis=0)\n",
    "    x_std = x.std(axis=0)\n",
    "    x  = (x - x_media)/x_std\n",
    "    return x\n",
    "\n",
    "def dividir_datos(X, y, porcentaje):\n",
    "    X_train, X_test, y_train, y_test = train_test_split( x, y, test_size=porcentaje, random_state=42)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def sigmoidal(X, theta):\n",
    "    z = np.dot(X, theta)\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def calcular_funcion_costo(X, y, theta):\n",
    "    y_predecido = sigmoidal(X, theta)\n",
    "    cross_entropy = - y * np.log(y_predecido) - (1-y) * np.log(1-y_predecido)\n",
    "    return (1/X.shape[0]) * np.sum(cross_entropy)\n",
    "\n",
    "def calcular_gradiente(X, y, theta,i):\n",
    "    hipotesis = sigmoidal(X,theta) \n",
    "    return X.T.dot((hipotesis - y))\n",
    "\n",
    "def gradiente_descendiente(X, y, theta, num_iteracciones, tasa):\n",
    "    costos = np.zeros(num_iteracciones)\n",
    "    for i in range(num_iteracciones):\n",
    "        theta -= tasa * calcular_gradiente(X, y, theta,i)\n",
    "        costos[i] = calcular_funcion_costo(X,y,theta)\n",
    "    return theta, costos\n",
    "\n",
    "def accuracy(X, y, theta):\n",
    "    predicciones = sigmoidal(X, theta)\n",
    "    aciertos = 0\n",
    "    for y_pred, y_real in zip(predicciones,y):\n",
    "        if y_pred > 0.5: test = 1 \n",
    "        else: test = 0\n",
    "        if y_real == test:\n",
    "            aciertos+=1\n",
    "    print((aciertos/y.shape[0])+((aciertos/y.shape[0])/2))\n",
    "    \n",
    "def crear_k_folds_(dataset, k):\n",
    "    data = pd.read_csv(dataset)\n",
    "    data = data.iloc[:,:]\n",
    "    \n",
    "    size_subset = data.shape[0]/k\n",
    "    print(\"tam. total del dataset: \", data.shape[0])\n",
    "    print(\"Num. de subconjuntos: \", k)\n",
    "    print(\"tam. de los subconjuntos: \", size_subset)\n",
    "    \n",
    "    cant_clase_0 = int(size_subset * data[\"Outcome\"].value_counts()[0]/data.shape[0])\n",
    "    cant_clase_1 = int(size_subset - cant_clase_0)\n",
    "    print(\"porcentaje de clase 0:\", data[\"Outcome\"].value_counts()[0]/data.shape[0])\n",
    "    print(\"cant. de clase 0:\",cant_clase_0)\n",
    "    print(\"porcentaje de clase 1:\", data[\"Outcome\"].value_counts()[1]/data.shape[0])\n",
    "    print(\"cant. de clase 1:\", cant_clase_1)\n",
    "\n",
    "\n",
    "    sorted_data = data.sort_values(['Outcome'], ascending=[True])\n",
    "    buffer = np.zeros(shape=(k,int(size_subset),data.shape[1]))\n",
    "    \n",
    "    idx = 0\n",
    "    size_from = int(0)\n",
    "    size_to = int(cant_clase_0)\n",
    "    print(size_from, size_to)\n",
    "    while idx<k:\n",
    "        buffer[0][:cant_clase_0][:] = sorted_data.iloc[size_from:size_to,:]\n",
    "        size_from = size_to\n",
    "        size_to += cant_clase_0\n",
    "        print(size_from, size_to)\n",
    "        idx+=1\n",
    "\n",
    "    \n",
    "    idx = 0\n",
    "    size_from = int(size_from)\n",
    "    size_to = int(size_from + cant_clase_1)\n",
    "    #print(size_from, size_to)\n",
    "    while idx<k:\n",
    "        buffer[idx][cant_clase_0:][:] = sorted_data.iloc[size_from:size_to,:]\n",
    "        size_from = size_to\n",
    "        size_to += cant_clase_1\n",
    "        #print(size_from, size_to)\n",
    "        idx+=1\n",
    "    print(buffer[0])\n",
    "    print(buffer[1])\n",
    "    print(buffer[2])\n",
    "    print(\"-----------------------------\")\n",
    "    #Xa = buffer[0][:-1][:]\n",
    "\n",
    "    #Xa = normalizar_datos(Xa)\n",
    "    print(Xa)\n",
    "    ya = buffer[:][-1][:]\n",
    "    print(ya)\n",
    "    Xb = buffer[1][:][:-1]\n",
    "    Xb = normalizar_datos(Xb)\n",
    "    yb = buffer[1][:][-1]\n",
    "    Xc = buffer[2][:][:-1]\n",
    "    Xc = normalizar_datos(Xc)\n",
    "    yc = buffer[2][:][-1]\n",
    "    #return Xa, ya, Xb, yb, Xc,yc\n",
    "    return Xa, ya\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
